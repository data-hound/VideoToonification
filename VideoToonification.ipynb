{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "hWzvw9N9Zkz7",
    "outputId": "04915d69-c72b-4519-847e-eb788e6282d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SMId4WOuaLMr"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f2dfb685a5d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# from google.colab.patches import cv2_imshow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "import cv2\n",
    "import os\n",
    "from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dHTg47Z4EeVx"
   },
   "source": [
    "A post that might help: https://stackoverflow.com/questions/1357403/how-to-cartoon-ify-an-image-programmatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SHRDPhnaMhy_"
   },
   "source": [
    "Blenderpy on github: https://github.com/TylerGubala/blenderpy\n",
    "Install on linux issue: https://github.com/TylerGubala/blenderpy/issues/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bw0dQXMibE3a"
   },
   "source": [
    "## Cartoonization-1\n",
    "Cartoonization Method taken from https://github.com/lutianming/cartoonizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ljj9iquRaNzQ"
   },
   "outputs": [],
   "source": [
    "def cartoonize(image):\n",
    "    \"\"\"\n",
    "    convert image into cartoon-like image\n",
    "    image: input PIL image\n",
    "    \"\"\"\n",
    "\n",
    "    output = np.array(image)\n",
    "    x, y, c = output.shape\n",
    "    # hists = []\n",
    "    for i in range(c):\n",
    "        output[:, :, i] = cv2.bilateralFilter(output[:, :, i], 5, 50, 50)\n",
    "        # hist, _ = np.histogram(output[:, :, i], bins=np.arange(256+1))\n",
    "        # hists.append(hist)\n",
    "    edge = cv2.Canny(output, 100, 200)\n",
    "\n",
    "    output = cv2.cvtColor(output, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    hists = []\n",
    "    #H\n",
    "    hist, _ = np.histogram(output[:, :, 0], bins=np.arange(180+1))\n",
    "    hists.append(hist)\n",
    "    #S\n",
    "    hist, _ = np.histogram(output[:, :, 1], bins=np.arange(256+1))\n",
    "    hists.append(hist)\n",
    "    #V\n",
    "    hist, _ = np.histogram(output[:, :, 2], bins=np.arange(256+1))\n",
    "    hists.append(hist)\n",
    "\n",
    "    C = []\n",
    "    for h in hists:\n",
    "        C.append(k_histogram(h))\n",
    "    \n",
    "    if(verbose):\n",
    "      print(\"centroids: {0}\".format(C))\n",
    "\n",
    "    output = output.reshape((-1, c))\n",
    "    for i in range(c):\n",
    "        channel = output[:, i]\n",
    "        index = np.argmin(np.abs(channel[:, np.newaxis] - C[i]), axis=1)\n",
    "        output[:, i] = C[i][index]\n",
    "    output = output.reshape((x, y, c))\n",
    "    output = cv2.cvtColor(output, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    contours, _ = cv2.findContours(edge,\n",
    "                                   cv2.RETR_EXTERNAL,\n",
    "                                   cv2.CHAIN_APPROX_NONE)\n",
    "    # for i in range(len(contours)):\n",
    "    #     tmp = contours[i]\n",
    "    #     contours[i] = cv2.approxPolyDP(tmp, 2, False)\n",
    "    cv2.drawContours(output, contours, -1, 0, thickness=1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_O6df9aqaSHB"
   },
   "outputs": [],
   "source": [
    "def update_C(C, hist):\n",
    "    \"\"\"\n",
    "    update centroids until they don't change\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        groups = defaultdict(list)\n",
    "        #assign pixel values\n",
    "        for i in range(len(hist)):\n",
    "            if hist[i] == 0:\n",
    "                continue\n",
    "            d = np.abs(C-i)\n",
    "            index = np.argmin(d)\n",
    "            groups[index].append(i)\n",
    "\n",
    "        new_C = np.array(C)\n",
    "        for i, indice in groups.items():\n",
    "            if np.sum(hist[indice]) == 0:\n",
    "                continue\n",
    "            new_C[i] = int(np.sum(indice*hist[indice])/np.sum(hist[indice]))\n",
    "        if np.sum(new_C-C) == 0:\n",
    "            break\n",
    "        C = new_C\n",
    "    return C, groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QPzRr32saU7J"
   },
   "outputs": [],
   "source": [
    "def k_histogram(hist):\n",
    "    \"\"\"\n",
    "    choose the best K for k-means and get the centroids\n",
    "    \"\"\"\n",
    "    alpha = 0.001              # p-value threshold for normaltest\n",
    "    N = 80                      # minimun group size for normaltest\n",
    "    C = np.array([128])\n",
    "\n",
    "    while True:\n",
    "        C, groups = update_C(C, hist)\n",
    "\n",
    "        #start increase K if possible\n",
    "        new_C = set()     # use set to avoid same value when seperating centroid\n",
    "        for i, indice in groups.items():\n",
    "            #if there are not enough values in the group, do not seperate\n",
    "            if len(indice) < N:\n",
    "                new_C.add(C[i])\n",
    "                continue\n",
    "\n",
    "            # judge whether we should seperate the centroid\n",
    "            # by testing if the values of the group is under a\n",
    "            # normal distribution\n",
    "            z, pval = stats.normaltest(hist[indice])\n",
    "            if pval < alpha:\n",
    "                #not a normal dist, seperate\n",
    "                left = 0 if i == 0 else C[i-1]\n",
    "                right = len(hist)-1 if i == len(C)-1 else C[i+1]\n",
    "                delta = right-left\n",
    "                if delta >= 3:\n",
    "                    c1 = (C[i]+left)/2\n",
    "                    c2 = (C[i]+right)/2\n",
    "                    new_C.add(c1)\n",
    "                    new_C.add(c2)\n",
    "                else:\n",
    "                    # though it is not a normal dist, we have no\n",
    "                    # extra space to seperate\n",
    "                    new_C.add(C[i])\n",
    "            else:\n",
    "                # normal dist, no need to seperate\n",
    "                new_C.add(C[i])\n",
    "        if len(new_C) == len(C):\n",
    "            break\n",
    "        else:\n",
    "            C = np.array(sorted(new_C))\n",
    "    return C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vg_vZdAebPKQ"
   },
   "source": [
    "## Cartoonization-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KYoPVkUtbO5q"
   },
   "outputs": [],
   "source": [
    "def make_image(a,N,p,input_image):\n",
    "\n",
    "    print (a)\n",
    "    print (N)\n",
    "    print (p)\n",
    "    #Phase 1 : color staircasing #########################################################################################################\n",
    "\n",
    "    # Then We Do Bilateral Filtering with k1 = kernal size and N = number of iterations\n",
    "    # We do Median Filtering\n",
    "    # Color quantization floor factor = a\n",
    "\n",
    "    for x in range(0,N):\n",
    "        bilateral_filtimg = cv2.bilateralFilter(input_image,9,75,75)\n",
    "\n",
    "    median_filtimg = cv2.medianBlur(bilateral_filtimg,5)\n",
    "\n",
    "    [rows,cols,c] = median_filtimg.shape\n",
    "    colorquantimg = median_filtimg\n",
    "    for i in range(0,rows):\n",
    "        for j in range(0,cols):\n",
    "            xb = median_filtimg.item(i,j,0)\n",
    "            xg = median_filtimg.item(i,j,1)\n",
    "            xr = median_filtimg.item(i,j,2)  \n",
    "            xb = math.floor(xb/a)*a \n",
    "            xg = math.floor(xg/a)*a\n",
    "            xr = math.floor(xr/a)*a\n",
    "            colorquantimg.itemset((i,j,0),xb)\n",
    "            colorquantimg.itemset((i,j,1),xg)\n",
    "            colorquantimg.itemset((i,j,2),xr)\n",
    "\n",
    "        # Phase2 : Edge Extraction ############################################################################################################\n",
    "\n",
    "        # Appy Median Filter to the image \n",
    "        # Canny Edge Detection\n",
    "        # Dialation of the detected edges\n",
    "        # Edgefilter\n",
    "        #p = cv2.getTrackbarPos('Canny Threshold','Toonified Image')\n",
    "\n",
    "    median_filtimg2 = cv2.medianBlur(input_image,5)\n",
    "#     cv2_imshow(median_filtimg2)\n",
    "\n",
    "    edges = cv2.Canny(median_filtimg2,p,2*p)\n",
    "    dialateimg =  cv2.dilate(edges,np.ones((3,3),'uint8'))\n",
    "    # dilateimg = edges\n",
    "    edges_inv = cv2.bitwise_not(dialateimg)\n",
    "\n",
    "#     cv2_imshow(edges)\n",
    "#     cv2_imshow(edges_inv)\n",
    "\n",
    "    # kernel = np.ones((5,5),np.uint8)\n",
    "    # erosion_edges = cv2.erode(edges_inv,kernel,iterations = 1)\n",
    "    # cv2_imshow(erosion_edges)\n",
    "\n",
    "    ret,thresh = cv2.threshold(edges_inv,127,255,0)\n",
    "    #cv2_imshow(thresh)\n",
    "    contours, hierarchy = cv2.findContours(thresh,1,2)\n",
    "    #(image, contours, contourIdx, color[, thickness[, lineType[, hierarchy[, maxLevel[, offset]]]]])\n",
    "    img_contours = cv2.drawContours(image=thresh, contours=contours, contourIdx=-1, color=(0,0,0), thickness=0)\n",
    "    print (img_contours)\n",
    "    cv2_imshow(img_contours)\n",
    "        #cv2.imshow('counters',img_contours)\n",
    "\n",
    "        ############################### Recombine both the images ##############################################################################\n",
    "    # global finalimg\n",
    "    finalimg = colorquantimg\n",
    "    for i in range(0,rows):\n",
    "        for j in range(0,cols):\n",
    "            if edges_inv.item(i,j) == 0:\n",
    "                finalimg.itemset((i,j,0),0)\n",
    "                finalimg.itemset((i,j,1),0)\n",
    "                finalimg.itemset((i,j,2),0)\n",
    "    # cv2_imshow(finalimg)       \n",
    "    cv2.waitKey(0)  \n",
    "\n",
    "    return finalimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W09AlGrYbZmc"
   },
   "source": [
    "## Test Cartoonize-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239
    },
    "colab_type": "code",
    "id": "1CDYdW7VatUw",
    "outputId": "ddfdcc8e-ea26-4c0b-e8db-9bc9d8bf5216"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-141f6d75711a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/*.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcartoonize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "input = '/content/drive/My Drive/*.jpg'\n",
    "image = cv2.imread(input)\n",
    "# cv2_imshow(image)\n",
    "start_time = time.time()\n",
    "output = cartoonize(image)\n",
    "end_time = time.time()\n",
    "t = end_time-start_time\n",
    "print('time: {0}s'.format(t))\n",
    "# cv2_imshow(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JvHjdzuNbg4q"
   },
   "source": [
    "## Test Cartoonize-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t4GodEuZbk7y"
   },
   "outputs": [],
   "source": [
    "def c2_driver(filename,a_ = 30, N_ = 5, p_ =55):\n",
    "  a = a_ #from_=10, to=50\n",
    "  N = N_ #from_=1, to=10\n",
    "  p = p_ #from_=10, to=100\n",
    "\n",
    "  input_image = cv2.imread(filename)\n",
    "  final = make_image(a,N,p,input_image)\n",
    "#   cv2_imshow(final) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eVkqrRTCbYu1"
   },
   "source": [
    "## Video Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SyUYtdiAt-Gv"
   },
   "source": [
    "Another movie library: https://pypi.org/project/mhmovie/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i9A9rf7yaYey"
   },
   "outputs": [],
   "source": [
    "import moviepy.editor as mpe\n",
    "\n",
    "def convert_video_cv2(input_file_location='/content/drive/My Drive/video.mp4', output_file_name = 'toonified.mp4', v=False):\n",
    "  global verbose\n",
    "  verbose = v\n",
    "  video = mpe.VideoFileClip(input_file_location)\n",
    "  audio = video.audio\n",
    "  # Required only if you want to add background audio on the present audio\n",
    "  # audio_background = mpe.AudioFileClip('some_background.mp3')\n",
    "  # final_audio = mpe.CompositeAudioClip([audio, audio_background])\n",
    "\n",
    "  cap = cv2.VideoCapture(input_file_location)\n",
    "\n",
    "  if (cap.isOpened()== False):\n",
    "      print(\"Error opening video stream or file\")\n",
    "\n",
    "  frame_width = int(cap.get(3))\n",
    "  frame_height = int(cap.get(4))\n",
    "\n",
    "  (major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "\n",
    "  if int(major_ver)  < 3 :\n",
    "    fps = cap.get(cv2.cv.CV_CAP_PROP_FPS)\n",
    "  else:\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "  \n",
    "  encod = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "\n",
    "  fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "  op_file = os.path.dirname(input_file_location) +'/'+ output_file_name\n",
    "  out = cv2.VideoWriter(op_file,fourcc, fps, (frame_width,frame_height))\n",
    "  \n",
    "  i=0\n",
    "  while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "      if (verbose):\n",
    "        print(\"Frame Number: \",i)\n",
    "      frame_ = cartoonize(frame)\n",
    "      out.write(frame_)\n",
    "      #cv2_imshow(frame)\n",
    "      # Press Q on keyboard to  exit\n",
    "      i=i+1\n",
    "      # if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "      #   break\n",
    "    else:\n",
    "      break\n",
    "  cap.release()\n",
    "\n",
    "\n",
    "  # We add the audio after the video has been made\n",
    "  final_vid = mpe.VideoFileClip(op_file)\n",
    "  final_clip = final_vid.set_audio(audio)\n",
    "  final_clip.write_videofile(op_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Xe_9jcaYt7r"
   },
   "outputs": [],
   "source": [
    "def add_audio(input_file_location='/content/drive/My Drive/video.mp4', output_file_name = 'toonified.mp4'):\n",
    "  video = mpe.VideoFileClip(input_file_location)\n",
    "  audio = video.audio\n",
    "  audio.write_audiofile(os.path.dirname(input_file_location) +'/'+'.mp3') \n",
    "  op_file = os.path.dirname(input_file_location) +'/'+ output_file_name\n",
    "  out_vid = mpe.VideoFileClip(op_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "kK5hZb4vi9mV",
    "outputId": "53e28e88-2877-421a-a7f5-1d5d3008f47f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
      "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
      "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b737280/45929032 bytes (1.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2039808/45929032 bytes (4.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3948544/45929032 bytes (8.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b6651904/45929032 bytes (14.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b10256384/45929032 bytes (22.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b13926400/45929032 bytes (30.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b17702912/45929032 bytes (38.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b21397504/45929032 bytes (46.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b25116672/45929032 bytes (54.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b28516352/45929032 bytes (62.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b32268288/45929032 bytes (70.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b35913728/45929032 bytes (78.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b39616512/45929032 bytes (86.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b43106304/45929032 bytes (93.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
      "  Done\n",
      "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
     ]
    }
   ],
   "source": [
    "import moviepy.editor as mpe\n",
    "\n",
    "def convert_video_mpe(input_file_location='/content/drive/My Drive/video.mp4', output_file_name = 'toonified.mp4', v=False):\n",
    "  global verbose\n",
    "  verbose = v\n",
    "  op_file = os.path.dirname(input_file_location) +'/'+ output_file_name\n",
    "  video = mpe.VideoFileClip(input_file_location)\n",
    "  audio = video.audio\n",
    "  new_vid = video.fl_image( cartoonize )\n",
    "  new_vid.write_videofile(op_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OPEG9U04lBU8"
   },
   "source": [
    "## Caller function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v8PQ09h3luwo"
   },
   "outputs": [],
   "source": [
    "convert_video_cv2('/content/drive/My Drive/<to location>/Agent327.mp4','Agent327_toonified_cv.mp4')\n",
    "# add_audio('/content/drive/My Drive/<to location>/OMTM.mp4','OMTM_toonified.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "colab_type": "code",
    "id": "2PmbeBuVjQ2J",
    "outputId": "1a3ed3eb-6a97-41c1-bd44-944a45a8f9e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video /content/drive/My Drive/Creatives/numb_toon.mp4\n",
      "[MoviePy] Writing audio in numb_toonTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4106/4106 [00:05<00:00, 697.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] Writing video /content/drive/My Drive/Creatives/numb_toon.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4469/4469 [11:54<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: /content/drive/My Drive/Creatives/numb_toon.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert_video_mpe('/content/drive/My Drive/<to location>/numb.mp4','numb_toon.mp4')\n",
    "convert_video_mpe('./numb.mp4','./numb_toon2.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pSNLNxPna2HY"
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('inp', help='Input video file full path')\n",
    "    parser.add_argument('output', help='Output file name. Only .mp4 format supported.')\n",
    "    # parser.add_argument('video format', help='format of video to be saved')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # image = Image.open(args.input)\n",
    "    # image = cv2.imread(args.input)\n",
    "    start_time = time.time()\n",
    "    # output = cartoonize(image)\n",
    "    convert_video(args.inp,args.output)\n",
    "    end_time = time.time()\n",
    "    t = end_time-start_time\n",
    "    print('time: {0}s'.format(t))\n",
    "    # cv2.imwrite(args.output, output)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Bw0dQXMibE3a",
    "vg_vZdAebPKQ"
   ],
   "name": "Video Toonification v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
